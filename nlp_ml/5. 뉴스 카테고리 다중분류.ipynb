{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p ~/aiffel/reuters_classifiaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ab4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d442c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03918d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8af64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21bdbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray(counts_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode 디버깅 해보기\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "index_to_word[0] = \"<pad>\"\n",
    "index_to_word[1] = \"<sos>\"\n",
    "index_to_word[2] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_list):\n",
    "    return ' '.join([index_to_word[index] for index in encoded_list])\n",
    "\n",
    "decode(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f527726",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode([4, 12000, 23, 133, 6, 30, 515])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [decode(x_train[i]) for i in range(len(x_train))]\n",
    "print(len(x_train))\n",
    "x_test = [decode(row) for row in x_test]\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "k = 5\n",
    "print(random.sample(x_train, k))\n",
    "print(random.sample(x_test, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1157e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac908eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_3 = model.predict_proba(tfidfv_test[3])[0]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11,5)\n",
    "plt.bar(model.classes_, probability_3)\n",
    "plt.xlim(-1, 21)\n",
    "plt.xticks(model.classes_)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model.predict(tfidfv_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f08921",
   "metadata": {},
   "source": [
    "- macro: 단순평균\n",
    "- weighted: 각 클래스에 속하는 표본의 개수로 가중평균\n",
    "- accuracy: 정확도. 전체 학습 데이터의 개수에서 클래스를 정확하게 맞춘 개수의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_confusion_matrix(model, x_test, y_test):  # , classes_name):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix(y_test, model.predict(x_test))\n",
    "    )  # , index=classes_name, columns=classes_name)\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    heatmap.yaxis.set_ticklabels(\n",
    "        heatmap.yaxis.get_ticklabels(), rotation=0, ha=\"right\", fontsize=12\n",
    "    )\n",
    "    heatmap.xaxis.set_ticklabels(\n",
    "        heatmap.xaxis.get_ticklabels(), rotation=45, ha=\"right\", fontsize=12\n",
    "    )\n",
    "    plt.ylabel(\"label\")\n",
    "    plt.xlabel(\"predicted value\")\n",
    "\n",
    "\n",
    "graph_confusion_matrix(model, tfidfv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac85b60",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes Classifier(CNB)\n",
    "> 나이브 베이지안 분류기는 독립 변수가 '조건부로 독립적'이라는 가정을 하기 때문에, 문서가 특정 분류에 속할 실제 확률을 사용할 때 문제가 발생할 수 있습니다.\n",
    "\n",
    "예를 들어 많은 샘플(sample)이 특정 클래스에 치우쳐져 있을 경우, 결정 경계의 가중치가 한쪽으로 치우쳐져 모델이 특정 클래스를 선호할 수 있습니다.\n",
    "\n",
    "데이터가 불균형할 경우를 대비해 나이브 베이즈 분류기를 보완한 것이 컴플리먼트 나이브 베이즈 분류기입니다. 컴플리먼트 나이브 베이즈 분류기는 데이터의 불균형을 고려하여 가중치를 부여하는 특징을 가지고 있습니다. 따라서 컴플리먼트 나이브 베이즈 분류기는 나이브 베이즈 분류기(MultinomialNB)보다 성능이 일반적으로 더 좋습니다.\n",
    "\n",
    "\n",
    "---\n",
    "### 라벨 불균형이 미치는 영향 예시\n",
    "나이브 베이지안 분류기의 결정 경계가 클래스 불균형 때문에 왜곡되는 현상을 수치적으로 이해하기 위해 간단한 예를 들어 설명하겠습니다.\n",
    "\n",
    "\n",
    "우리가 두 개의 클래스 A와 B를 가진 이진 분류 문제를 다룬다고 가정해 봅시다. 여기서 클래스 A에 속하는 샘플이 90%, 클래스 B에 속하는 샘플이 10%라고 가정합니다. 또한, 단 하나의 특성 $(X)$를 가지고 있으며, 이 특성의 값은 0과 1 중 하나입니다.\n",
    "\n",
    "#### 데이터 분포\n",
    "- 클래스 A (90%): $[X=0]$ 50%, $[X=1]$ 50%\n",
    "- 클래스 B (10%): $[X=0]$ 20%, $[X=1]$ 80%\n",
    "\n",
    "즉, 클래스 A에 속하는 샘플이 훨씬 많고, 클래스 B에 속하는 샘플은 적습니다. 나이브 베이지안 분류기는 각 클래스의 사후 확률을 계산하여 가장 높은 사후 확률을 가진 클래스로 분류합니다.\n",
    "\n",
    "### 나이브 베이지안 분류기 계산 과정\n",
    "\n",
    "1. **사전 확률**:\n",
    "    - $(P(A) = 0.9)$\n",
    "    - $(P(B) = 0.1)$\n",
    "\n",
    "2. **우도 (Likelihood)**:\n",
    "    - $(P(X=0|A) = 0.5)$\n",
    "    - $(P(X=1|A) = 0.5)$\n",
    "    - $(P(X=0|B) = 0.2)$\n",
    "    - $(P(X=1|B) = 0.8)$\n",
    "\n",
    "3. **사후 확률 계산**:\n",
    "    나이브 베이지안 분류기는 베이즈 정리를 사용하여 사후 확률을 계산합니다.\n",
    "    \n",
    "    $[\n",
    "    P(A|X) = \\frac{P(X|A) \\cdot P(A)}{P(X)}\n",
    "    ]$\n",
    "    \n",
    "    $[\n",
    "    P(B|X) = \\frac{P(X|B) \\cdot P(B)}{P(X)}\n",
    "    ]$\n",
    "\n",
    "### 분류 예시\n",
    "\n",
    "#### 케이스 1: $(X = 0)$ 일 때\n",
    "- $(P(X=0) = P(X=0|A) \\cdot P(A) + P(X=0|B) \\cdot P(B) = 0.5 \\cdot 0.9 + 0.2 \\cdot 0.1 = 0.45 + 0.02 = 0.47)$\n",
    "\n",
    "- $(P(A|X=0) = \\frac{P(X=0|A) \\cdot P(A)}{P(X=0)} = \\frac{0.5 \\cdot 0.9}{0.47} \\approx 0.957)$\n",
    "\n",
    "- $(P(B|X=0) = \\frac{P(X=0|B) \\cdot P(B)}{P(X=0)} = \\frac{0.2 \\cdot 0.1}{0.47} \\approx 0.043)$\n",
    "\n",
    "=> 이 경우, 나이브 베이지안 분류기는 클래스 A로 분류합니다.\n",
    "\n",
    "#### 케이스 2: $(X = 1)$ 일 때\n",
    "- $(P(X=1) = P(X=1|A) \\cdot P(A) + P(X=1|B) \\cdot P(B) = 0.5 \\cdot 0.9 + 0.8 \\cdot 0.1 = 0.45 + 0.08 = 0.53)$\n",
    "\n",
    "- $(P(A|X=1) = \\frac{P(X=1|A) \\cdot P(A)}{P(X=1)} = \\frac{0.5 \\cdot 0.9}{0.53} \\approx 0.849)$\n",
    "\n",
    "- $(P(B|X=1) = \\frac{P(X=1|B) \\cdot P(B)}{P(X=1)} = \\frac{0.8 \\cdot 0.1}{0.53} \\approx 0.151)$\n",
    "\n",
    "=> 이 경우에도 나이브 베이지안 분류기는 클래스 A로 분류합니다.\n",
    "\n",
    "### 문제점\n",
    "이 예시에서 보듯이, 클래스 B의 샘플이 상대적으로 적기 때문에, 모델은 특성 값이 1인 경우에도 클래스 A로 분류하는 경향이 있습니다. 이는 클래스 불균형으로 인해 모델이 클래스 B를 과소평가하게 되는 예시입니다.\n",
    "\n",
    "결과적으로, 실제로는 $(X=1)$일 때 클래스 B일 가능성이 높지만, 나이브 베이지안 분류기는 클래스 A로 잘못 분류하게 됩니다. 이로 인해 결정 경계가 왜곡되고, 클래스 B의 중요도를 무시하게 되는 문제가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10d262d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ce6c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2e341",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f56687",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000, verbose=True)\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45795d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6726cf1",
   "metadata": {},
   "source": [
    "## SVM\n",
    "- descision boundary\n",
    "- support vector: Decision Boundary와 가장 가까운 각 클래스의 데이터를 서포트 벡터라고 한다. Decision Boundary에 해당되는 벡터가 아니다.\n",
    "- cost: descision boundary와 margin간의 간격 (margin과 반비례)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "090e6c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=3000, penalty='l1')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddc1ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7876224398931434\n"
     ]
    }
   ],
   "source": [
    "prev = lsvc.predict(tfidfv_test)\n",
    "print(\"정확도:\", accuracy_score(y_test, prev)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542c9ad",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "> 트리 계열의 모델들은 고차원이고 희소한 데이터에 대해서는 성능이 나오지 않는다는 특징이 있습니다. \n",
    "\n",
    "DTM이나 TF-IDF 행렬의 경우 고차원이면서 대부분의 값이 0인 희소한 데이터이므로 트리 계열의 모델보다는 선형 분류 모델을 통해 접근하는 것이 더 나은 접근일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd1070fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87ef883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6202137132680321\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2d149",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9ed1aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bfd1328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.674087266251113\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8dab1",
   "metadata": {},
   "source": [
    "## Gradient Boosting classifier\n",
    "\n",
    "> 그래디언트 부스팅 트리는 일부 특성을 무시한다는 특징을 가지고 있습니다. 그래서 보통 랜덤 포레스트를 먼저 사용해보고, 성능이나 예측 시간 면에서 만족스럽지 않은 경우에 그래디언트 부스팅 트리를 시도해보는 것이 좋습니다.\n",
    "\n",
    "일반적으로 1 ~ 5 정도의 깊지 않은 트리를 사용하므로 메모리도 적게 사용하고 예측도 빠릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c16ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15분 정도 소요될 수 있습니다.\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "381df2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7662511130899377\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d3850f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       444866     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.43889D+04    |proj g|=  2.96374D+03\n",
      "\n",
      "At iterate   50    f=  1.30717D+03    |proj g|=  1.63867D+01\n",
      "\n",
      "At iterate  100    f=  4.87098D+02    |proj g|=  1.84201D+00\n",
      "\n",
      "At iterate  150    f=  4.62244D+02    |proj g|=  6.86419D-01\n",
      "\n",
      "At iterate  200    f=  4.59886D+02    |proj g|=  6.36858D-01\n",
      "\n",
      "At iterate  250    f=  4.59097D+02    |proj g|=  3.70866D-01\n",
      "\n",
      "At iterate  300    f=  4.56964D+02    |proj g|=  1.24828D+00\n",
      "\n",
      "At iterate  350    f=  4.55066D+02    |proj g|=  1.43875D-01\n",
      "\n",
      "At iterate  400    f=  4.53239D+02    |proj g|=  3.17502D-01\n",
      "\n",
      "At iterate  450    f=  4.51876D+02    |proj g|=  2.98869D-01\n",
      "\n",
      "At iterate  500    f=  4.50581D+02    |proj g|=  1.51322D+00\n",
      "\n",
      "At iterate  550    f=  4.49404D+02    |proj g|=  2.27625D-01\n",
      "\n",
      "At iterate  600    f=  4.48576D+02    |proj g|=  2.10635D-01\n",
      "\n",
      "At iterate  650    f=  4.47963D+02    |proj g|=  1.89320D-01\n",
      "\n",
      "At iterate  700    f=  4.47494D+02    |proj g|=  5.63430D-01\n",
      "\n",
      "At iterate  750    f=  4.47017D+02    |proj g|=  5.36448D-01\n",
      "\n",
      "At iterate  800    f=  4.46606D+02    |proj g|=  2.50959D-01\n",
      "\n",
      "At iterate  850    f=  4.46362D+02    |proj g|=  2.03450D-01\n",
      "\n",
      "At iterate  900    f=  4.46196D+02    |proj g|=  1.22841D-01\n",
      "\n",
      "At iterate  950    f=  4.46055D+02    |proj g|=  1.50139D-01\n",
      "\n",
      "At iterate 1000    f=  4.45945D+02    |proj g|=  2.58468D-01\n",
      "\n",
      "At iterate 1050    f=  4.45853D+02    |proj g|=  8.22595D-02\n",
      "\n",
      "At iterate 1100    f=  4.45790D+02    |proj g|=  5.72190D-02\n",
      "\n",
      "At iterate 1150    f=  4.45737D+02    |proj g|=  3.39328D-02\n",
      "\n",
      "At iterate 1200    f=  4.45695D+02    |proj g|=  2.35433D-02\n",
      "\n",
      "At iterate 1250    f=  4.45666D+02    |proj g|=  2.73782D-02\n",
      "\n",
      "At iterate 1300    f=  4.45642D+02    |proj g|=  1.06528D-01\n",
      "\n",
      "At iterate 1350    f=  4.45624D+02    |proj g|=  4.09142D-02\n",
      "\n",
      "At iterate 1400    f=  4.45612D+02    |proj g|=  5.96398D-02\n",
      "\n",
      "At iterate 1450    f=  4.45602D+02    |proj g|=  1.80146D-02\n",
      "\n",
      "At iterate 1500    f=  4.45597D+02    |proj g|=  1.40566D-02\n",
      "\n",
      "At iterate 1550    f=  4.45593D+02    |proj g|=  1.70559D-02\n",
      "\n",
      "At iterate 1600    f=  4.45589D+02    |proj g|=  1.28699D-02\n",
      "\n",
      "At iterate 1650    f=  4.45586D+02    |proj g|=  1.11638D-02\n",
      "\n",
      "At iterate 1700    f=  4.45583D+02    |proj g|=  1.17761D-02\n",
      "\n",
      "At iterate 1750    f=  4.45581D+02    |proj g|=  1.05688D-02\n",
      "\n",
      "At iterate 1800    f=  4.45580D+02    |proj g|=  5.25307D-03\n",
      "\n",
      "At iterate 1850    f=  4.45579D+02    |proj g|=  1.68388D-02\n",
      "\n",
      "At iterate 1900    f=  4.45578D+02    |proj g|=  4.82349D-03\n",
      "\n",
      "At iterate 1950    f=  4.45577D+02    |proj g|=  3.85002D-02\n",
      "\n",
      "At iterate 2000    f=  4.45577D+02    |proj g|=  2.20864D-03\n",
      "\n",
      "At iterate 2050    f=  4.45576D+02    |proj g|=  1.54750D-02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       444866     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.43889D+04    |proj g|=  2.96374D+03\n",
      "\n",
      "At iterate   50    f=  1.30717D+03    |proj g|=  1.63867D+01\n",
      "\n",
      "At iterate  100    f=  4.87098D+02    |proj g|=  1.84202D+00\n",
      "\n",
      "At iterate  150    f=  4.62249D+02    |proj g|=  6.82251D-01\n",
      "\n",
      "At iterate  200    f=  4.59442D+02    |proj g|=  9.64681D-01\n",
      "\n",
      "At iterate  250    f=  4.58524D+02    |proj g|=  2.38297D-01\n",
      "\n",
      "At iterate  300    f=  4.56756D+02    |proj g|=  6.43334D-01\n",
      "\n",
      "At iterate  350    f=  4.55262D+02    |proj g|=  1.53717D-01\n",
      "\n",
      "At iterate  400    f=  4.53879D+02    |proj g|=  8.27339D-01\n",
      "\n",
      "At iterate  450    f=  4.52505D+02    |proj g|=  4.14486D-01\n",
      "\n",
      "At iterate  500    f=  4.51214D+02    |proj g|=  7.87313D-01\n",
      "\n",
      "At iterate  550    f=  4.49830D+02    |proj g|=  1.52251D-01\n",
      "\n",
      "At iterate  600    f=  4.48705D+02    |proj g|=  3.87496D-01\n",
      "\n",
      "At iterate  650    f=  4.47917D+02    |proj g|=  9.19500D-02\n",
      "\n",
      "At iterate  700    f=  4.47330D+02    |proj g|=  1.79744D-01\n",
      "\n",
      "At iterate  750    f=  4.46900D+02    |proj g|=  2.06894D-01\n",
      "\n",
      "At iterate  800    f=  4.46518D+02    |proj g|=  5.38714D-02\n",
      "\n",
      "At iterate  850    f=  4.46246D+02    |proj g|=  1.30453D-01\n",
      "\n",
      "At iterate  900    f=  4.46066D+02    |proj g|=  6.58951D-02\n",
      "\n",
      "At iterate  950    f=  4.45954D+02    |proj g|=  1.32973D-01\n",
      "\n",
      "At iterate 1000    f=  4.45859D+02    |proj g|=  1.17121D-01\n",
      "\n",
      "At iterate 1050    f=  4.45788D+02    |proj g|=  7.09047D-02\n",
      "\n",
      "At iterate 1100    f=  4.45738D+02    |proj g|=  2.86352D-01\n",
      "\n",
      "At iterate 1150    f=  4.45706D+02    |proj g|=  7.40775D-02\n",
      "\n",
      "At iterate 1200    f=  4.45676D+02    |proj g|=  3.00101D-02\n",
      "\n",
      "At iterate 1250    f=  4.45654D+02    |proj g|=  1.86419D-02\n",
      "\n",
      "At iterate 1300    f=  4.45636D+02    |proj g|=  3.11390D-02\n",
      "\n",
      "At iterate 1350    f=  4.45624D+02    |proj g|=  2.88706D-02\n",
      "\n",
      "At iterate 1400    f=  4.45614D+02    |proj g|=  7.82615D-03\n",
      "\n",
      "At iterate 1450    f=  4.45607D+02    |proj g|=  1.17939D-01\n",
      "\n",
      "At iterate 1500    f=  4.45599D+02    |proj g|=  2.17350D-02\n",
      "\n",
      "At iterate 1550    f=  4.45593D+02    |proj g|=  1.37500D-02\n",
      "\n",
      "At iterate 1600    f=  4.45589D+02    |proj g|=  1.82332D-02\n",
      "\n",
      "At iterate 1650    f=  4.45587D+02    |proj g|=  1.60711D-02\n",
      "\n",
      "At iterate 1700    f=  4.45584D+02    |proj g|=  1.73223D-02\n",
      "\n",
      "At iterate 1750    f=  4.45582D+02    |proj g|=  1.24074D-02\n",
      "\n",
      "At iterate 1800    f=  4.45580D+02    |proj g|=  8.69829D-03\n",
      "\n",
      "At iterate 1850    f=  4.45579D+02    |proj g|=  1.25327D-02\n",
      "\n",
      "At iterate 1900    f=  4.45578D+02    |proj g|=  1.08024D-02\n",
      "\n",
      "At iterate 1950    f=  4.45577D+02    |proj g|=  8.32368D-03\n",
      "\n",
      "At iterate 2000    f=  4.45577D+02    |proj g|=  1.49132D-02\n",
      "\n",
      "At iterate 2050    f=  4.45576D+02    |proj g|=  2.23899D-03\n",
      "\n",
      "At iterate 2100    f=  4.45576D+02    |proj g|=  6.51448D-03\n",
      "\n",
      "At iterate 2150    f=  4.45576D+02    |proj g|=  1.29456D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****   2157   2341      1     0     0   9.913D-03   4.456D+02\n",
      "  F =   445.57582700571220     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       444866     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.43889D+04    |proj g|=  2.96374D+03\n",
      "\n",
      "At iterate   50    f=  1.30717D+03    |proj g|=  1.63867D+01\n",
      "\n",
      "At iterate  100    f=  4.87098D+02    |proj g|=  1.84202D+00\n",
      "\n",
      "At iterate  150    f=  4.62249D+02    |proj g|=  6.82251D-01\n",
      "\n",
      "At iterate  200    f=  4.59442D+02    |proj g|=  9.64681D-01\n",
      "\n",
      "At iterate  250    f=  4.58524D+02    |proj g|=  2.38297D-01\n",
      "\n",
      "At iterate  300    f=  4.56756D+02    |proj g|=  6.43334D-01\n",
      "\n",
      "At iterate  350    f=  4.55262D+02    |proj g|=  1.53717D-01\n",
      "\n",
      "At iterate  400    f=  4.53879D+02    |proj g|=  8.27339D-01\n",
      "\n",
      "At iterate  450    f=  4.52505D+02    |proj g|=  4.14486D-01\n",
      "\n",
      "At iterate  500    f=  4.51214D+02    |proj g|=  7.87313D-01\n",
      "\n",
      "At iterate  550    f=  4.49830D+02    |proj g|=  1.52251D-01\n",
      "\n",
      "At iterate  600    f=  4.48705D+02    |proj g|=  3.87496D-01\n",
      "\n",
      "At iterate  650    f=  4.47917D+02    |proj g|=  9.19500D-02\n",
      "\n",
      "At iterate  700    f=  4.47330D+02    |proj g|=  1.79744D-01\n",
      "\n",
      "At iterate  750    f=  4.46900D+02    |proj g|=  2.06894D-01\n",
      "\n",
      "At iterate  800    f=  4.46518D+02    |proj g|=  5.38714D-02\n",
      "\n",
      "At iterate  850    f=  4.46246D+02    |proj g|=  1.30453D-01\n",
      "\n",
      "At iterate  900    f=  4.46066D+02    |proj g|=  6.58951D-02\n",
      "\n",
      "At iterate  950    f=  4.45954D+02    |proj g|=  1.32973D-01\n",
      "\n",
      "At iterate 1000    f=  4.45859D+02    |proj g|=  1.17121D-01\n",
      "\n",
      "At iterate 1050    f=  4.45788D+02    |proj g|=  7.09047D-02\n",
      "\n",
      "At iterate 1100    f=  4.45738D+02    |proj g|=  2.86352D-01\n",
      "\n",
      "At iterate 1150    f=  4.45706D+02    |proj g|=  7.40775D-02\n",
      "\n",
      "At iterate 1200    f=  4.45676D+02    |proj g|=  3.00101D-02\n",
      "\n",
      "At iterate 1250    f=  4.45654D+02    |proj g|=  1.86419D-02\n",
      "\n",
      "At iterate 1300    f=  4.45636D+02    |proj g|=  3.11390D-02\n",
      "\n",
      "At iterate 1350    f=  4.45624D+02    |proj g|=  2.88706D-02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (1 of 3) Processing lr, total=10.8min\n",
      "[Voting] ....................... (2 of 3) Processing cb, total=   0.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/1671909424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m voting_classifier = VotingClassifier(estimators=[\n\u001b[1;32m      2\u001b[0m         ('lr', lr), ('cb', cb), ('grbt', grbt)], voting='soft', verbose=True)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvoting_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidfv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m     75\u001b[0m             delayed(_fit_single_estimator)(\n\u001b[1;32m     76\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             residual = loss.negative_gradient(\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m    822\u001b[0m         return y - np.nan_to_num(\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "        ('lr', lr), ('cb', cb), ('grbt', grbt)], voting='soft', verbose=True)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ac3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
